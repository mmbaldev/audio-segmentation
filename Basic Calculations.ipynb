{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import librosa.display\n",
    "from scipy.signal import find_peaks\n",
    "import pandas as pd\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import IPython.display as ipd\n",
    "from sklearn.metrics import classification_report\n",
    "import os\n",
    "from numpy import linalg as LA\n",
    "import warnings\n",
    "import pickle\n",
    "warnings.simplefilter(\"ignore\")\n",
    "%matplotlib tk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = 44100\n",
    "n_fft = int(sr * (20/1000)) # frequency resolution for basic features\n",
    "# n_fft = 441000\n",
    "window_length = n_fft #frame size for basic features\n",
    "hop_length = window_length // 2 #time resolution for basic features\n",
    "segment_size = sr * 1 # 1 second will be used for segmenting and statistics on short time features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Audio Samples Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_names = os.listdir('./samples')\n",
    "audio_files_paths = [ s for s in files_names if s.endswith('.mp3')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(audio_sample_labeling, frame_length, hop_length):\n",
    "    pad_size = hop_length-((audio_sample_labeling.size-frame_length)%hop_length)\n",
    "    if pad_size == hop_length: pad_size = 0\n",
    "    return np.pad(audio_sample_labeling, (0, pad_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audios = {}\n",
    "srs = {}\n",
    "labels_csv = {}\n",
    "for audio_file_name in audio_files_paths:\n",
    "    print('loading audio file ' + audio_file_name + '...')\n",
    "    audio_path = './samples/' + audio_file_name\n",
    "    audios[audio_file_name], srs[audio_file_name] = librosa.load(audio_path, sr=None)\n",
    "    audios[audio_file_name] = padding(audios[audio_file_name], segment_size, segment_size//4)\n",
    "    print(f'loading the labels from csv')\n",
    "    labels_csv[audio_file_name] = pd.read_csv(f'./samples/{audio_file_name[:-4]}.csv',header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define training  and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_size = 0\n",
    "for audio in audios.values(): total_size+= len(audio)\n",
    "train_size = total_size * 0.7\n",
    "size = 0\n",
    "train_audios_names = []\n",
    "for key, value in audios.items():\n",
    "    if size + len(value) <= train_size:\n",
    "        size+= len(value)\n",
    "        train_audios_names += [key]\n",
    "\n",
    "print(f'Training data percentage is: {size * 100 /total_size}%')\n",
    "print(f'Audio files used for training', train_audios_names)\n",
    "test_audios_names = [key for key in audios.keys() if key not in train_audios_names]\n",
    "print(f'Audio files used for testing', test_audios_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audios Sample Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We put the labels for each sample of all audios (based on labels csv) Labels: silence=0, music=1, speech=2, music&speech=3\n",
    "def sample_labeling(labels_csv, audio):    \n",
    "    labels = np.zeros(audio.size).astype(np.int32)\n",
    "    for start, duration, label in labels_csv.values:\n",
    "        start_, duration_ = np.floor([start*sr, duration*sr]).astype(np.int32)\n",
    "        seg = labels[start_:start_+duration_]\n",
    "        if label == 's': \n",
    "            labels[start_:start_+duration_] += 2\n",
    "        elif label == 'm': \n",
    "            labels[start_:start_+duration_] += 1          \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create sample labeling for all audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sample_labeling = {}\n",
    "testing_sample_labeling = {}\n",
    "for key, audio in audios.items():\n",
    "    if key in train_audios_names:\n",
    "        training_sample_labeling[key] = sample_labeling(labels_csv[key], audio)\n",
    "    elif key in test_audios_names:\n",
    "        testing_sample_labeling[key] = sample_labeling(labels_csv[key], audio)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frame Labeling, normalized based on majority of samples in a frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_labeling(audio_sample_labeling, frame_length, hop_length, multi_label=False):\n",
    "    def label_per_frame():\n",
    "        start = 0\n",
    "        while start+frame_length <= audio_sample_labeling.size:\n",
    "            frame = audio_sample_labeling[start:start+frame_length]\n",
    "            if multi_label: \n",
    "                labels, counts = np.unique(frame, return_counts=True)\n",
    "                yield labels[np.argmax(counts)]\n",
    "            else:   \n",
    "                speech_count = np.sum(frame >= 2)\n",
    "                other_count = np.sum((frame < 2) & (frame == 3))\n",
    "                yield 1 if speech_count > other_count else 0\n",
    "            start += hop_length\n",
    "    return list(label_per_frame())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_frame_labeling = {}\n",
    "testing_frame_labeling = {}\n",
    "for key, audio in audios.items():\n",
    "    if key in train_audios_names:\n",
    "        training_frame_labeling[key] = frame_labeling(training_sample_labeling[key], segment_size, segment_size//4)\n",
    "    elif key in test_audios_names:\n",
    "        testing_frame_labeling[key] = frame_labeling(testing_sample_labeling[key], segment_size, segment_size//4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Basic Variable Jsons in hard disk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labling_type = 'bi_label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are doing this in order to load the audios and other calculated variables quickly later\n",
    "with open('pickles/audios.pickle', 'wb') as handle:\n",
    "    pickle.dump(audios, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('pickles/srs.pickle', 'wb') as handle:\n",
    "    pickle.dump(srs, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('pickles/train_audios_names.pickle', 'wb') as handle:\n",
    "    pickle.dump(train_audios_names, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('pickles/test_audios_names.pickle', 'wb') as handle:\n",
    "    pickle.dump(test_audios_names, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(f'pickles/{labling_type}/training_sample_labeling.pickle', 'wb') as handle:\n",
    "    pickle.dump(training_sample_labeling, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(f'pickles/{labling_type}/testing_sample_labeling.pickle', 'wb') as handle:\n",
    "    pickle.dump(testing_sample_labeling, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(f'pickles/{labling_type}/training_frame_labeling.pickle', 'wb') as handle:\n",
    "    pickle.dump(training_frame_labeling, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(f'pickles/{labling_type}/testing_frame_labeling.pickle', 'wb') as handle:\n",
    "    pickle.dump(testing_frame_labeling, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
