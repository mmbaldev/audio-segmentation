{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import librosa.display\n",
    "from scipy.signal import find_peaks\n",
    "import pandas as pd\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn import svm\n",
    "import IPython.display as ipd\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy import stats\n",
    "import os\n",
    "from numpy import linalg as LA\n",
    "import warnings\n",
    "import pickle\n",
    "warnings.simplefilter(\"ignore\")\n",
    "%matplotlib tk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = 44100\n",
    "n_fft = int(sr * (20/1000)) # frequency resolution for basic features\n",
    "# n_fft = 441000\n",
    "window_length = n_fft #frame size for basic features\n",
    "hop_length = window_length // 2 #time resolution for basic features\n",
    "segment_size = sr * 1 # 1 second will be used for segmenting and statistics on short time features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Basic Variable Jsons from hard disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labling_type = 'bi_label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('./pickles/audios.pickle', 'rb') as handle:\n",
    "    audios = pickle.load(handle)\n",
    "with open('./pickles/audios.pickle', 'rb') as handle:\n",
    "    srs = pickle.load(handle)\n",
    "with open('./pickles/train_audios_names.pickle', 'rb') as handle:\n",
    "    train_audios_names = pickle.load(handle)\n",
    "with open('./pickles/test_audios_names.pickle', 'rb') as handle:\n",
    "    test_audios_names = pickle.load(handle)\n",
    "# with open(f'./pickles/{labling_type}/training_sample_labeling.pickle', 'rb') as handle:\n",
    "#     training_sample_labeling = pickle.load(handle)\n",
    "# with open(f'./pickles/{labling_type}/testing_sample_labeling.pickle', 'rb') as handle:\n",
    "#     testing_sample_labeling = pickle.load(handle)\n",
    "with open(f'./pickles/{labling_type}/training_frame_labeling.pickle', 'rb') as handle:\n",
    "    training_frame_labeling = pickle.load(handle)\n",
    "with open(f'./pickles/{labling_type}/testing_frame_labeling.pickle', 'rb') as handle:\n",
    "    testing_frame_labeling = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_features(audio, n_fft, hop_length, window_length, center=False):\n",
    "    chroma = librosa.feature.chroma_stft(audio, sr=sr, n_fft=n_fft, win_length=window_length, hop_length=hop_length, center=center)\n",
    "    S = librosa.feature.melspectrogram(y=audio, sr=sr, hop_length=hop_length, n_fft=n_fft, win_length=window_length, center=center)\n",
    "    mfcc = librosa.feature.mfcc(S=librosa.power_to_db(S))\n",
    "    S_diff = np.diff(S, prepend=0)\n",
    "    flux = LA.norm(S_diff, ord=2, axis=0) ** 2\n",
    "    stft = librosa.stft(audio, n_fft=n_fft, hop_length=hop_length, win_length=window_length, center=center)\n",
    "    S, phase = librosa.magphase(stft)\n",
    "    rms = librosa.feature.rms(S=S, frame_length=window_length, hop_length=hop_length, center=center)[0]\n",
    "    frequencies = librosa.fft_frequencies(sr=sr, n_fft=n_fft)\n",
    "    cent = librosa.feature.spectral_centroid(S=S, freq=frequencies)[0]\n",
    "    rolloff = librosa.feature.spectral_rolloff(S=S, freq=frequencies, roll_percent=0.95)[0]\n",
    "    zero_crossing_rate = librosa.feature.zero_crossing_rate(audio,center=center, frame_length=window_length, hop_length=hop_length)[0]\n",
    "    flatness = librosa.feature.spectral_flatness(S=S,center=center)[0]\n",
    "    bandwidth = librosa.feature.spectral_bandwidth(S=S, sr=sr, hop_length=hop_length, win_length=window_length, center=center)[0]\n",
    "    \n",
    "    return {'cent': cent, 'rolloff': rolloff, 'flux': flux, 'zero_crossing_rate': zero_crossing_rate, 'rms': rms, 'flatness': flatness,\n",
    "    'chroma': chroma, 'mfcc': mfcc, 'bandwidth': bandwidth}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate features for all audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating audio(eatmycountry1609.mp3) features...\n",
      "calculating audio(theconcert16.mp3) features...\n",
      "calculating audio(ConscinciasParalelasN11-OEspelhoEOReflexoFantasiasEPerplexidadesParte413-12-1994.mp3) features...\n",
      "calculating audio(ConscinciasParalelasN7-OsSentidosOSentirEAsNormasParte715-1-1994.mp3) features...\n",
      "calculating audio(theconcert2.mp3) features...\n",
      "calculating audio(UTMA-26.mp3) features...\n",
      "calculating audio(ConscinciasParalelasN3-OsSentidosOSentirEAsNormasParte318-10-1994.mp3) features...\n"
     ]
    }
   ],
   "source": [
    "training_features = {}\n",
    "testing_features = {}\n",
    "\n",
    "for i,v in audios.items():\n",
    "    print(f'calculating audio({i}) features...')\n",
    "    features_list = basic_features(v, n_fft, hop_length, window_length)\n",
    "    if i in train_audios_names:\n",
    "        training_features[i] = features_list\n",
    "    elif i in test_audios_names:\n",
    "        testing_features[i] = features_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save basic training and testing features on hard disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickles/training_basic_features.pickle', 'wb') as handle:\n",
    "    pickle.dump(training_features, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('pickles/testing_basic_features.pickle', 'wb') as handle:\n",
    "    pickle.dump(testing_features, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can load basic features from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./pickles/training_basic_features.pickle', 'rb') as handle:\n",
    "    training_features = pickle.load(handle)\n",
    "with open('./pickles/testing_basic_features.pickle', 'rb') as handle:\n",
    "    testing_features = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving Statistics Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_method(arr_, window_length, hop_length, method, mode='valid'):\n",
    "    arr = np.array(arr_, ndmin=2)\n",
    "    def method_per_frame():\n",
    "        start = 0\n",
    "        if mode == 'valid':\n",
    "            while start+window_length <= arr.shape[1]:\n",
    "                yield getattr(np, method)(arr[:, start:start+window_length], axis=1, keepdims=True)\n",
    "                start += hop_length\n",
    "        else:\n",
    "            while start < arr.shape[1]:\n",
    "                yield getattr(np, method)(arr[:, start:start+window_length], axis=1, keepdims=True)\n",
    "                start += hop_length\n",
    "    return np.hstack(list(method_per_frame()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizing(y_, model='z-score'):\n",
    "    y = y_.copy()\n",
    "    if model == 'z-score':\n",
    "        return stats.zscore(y)\n",
    "    mean_ = np.mean(y, axis=0, keepdims=True)\n",
    "    y -= np.repeat(mean_, y.shape[0], axis=0)\n",
    "    max_ = np.max(np.abs(y), axis=0, keepdims=True)\n",
    "    min_ = np.min(y, axis=0, keepdims=True)\n",
    "    range_ = (max_ - min_)/2\n",
    "    y /= np.repeat(max_, y.shape[0], axis=0)\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_features = {**training_features, **testing_features}\n",
    "merged_labels = {**training_frame_labeling, **testing_frame_labeling}\n",
    "all_audio_names = list(merged_labels.keys())\n",
    "\n",
    "test_audios_names = list(testing_features.keys())\n",
    "train_audios_names = list(training_features.keys())\n",
    "np.random.seed(51328973)\n",
    "np.random.shuffle(all_audio_names)\n",
    "audio_lens = [len(merged_labels[audio_name]) for audio_name in all_audio_names]\n",
    "total_lens = np.sum(audio_lens)\n",
    "split_ratio = 0.8\n",
    "i = 0\n",
    "split_ratio_i = 0\n",
    "while np.abs(split_ratio_i-split_ratio) > np.abs(split_ratio-(np.sum(audio_lens[:i+1])/total_lens)):\n",
    "    i += 1\n",
    "    split_ratio_i = np.sum(audio_lens[:i])/total_lens\n",
    "train_audios_names = all_audio_names[:i]\n",
    "test_audios_names = all_audio_names[i:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Audios ['ConscinciasParalelasN11-OEspelhoEOReflexoFantasiasEPerplexidadesParte413-12-1994.mp3', 'eatmycountry1609.mp3', 'theconcert16.mp3', 'ConscinciasParalelasN7-OsSentidosOSentirEAsNormasParte715-1-1994.mp3', 'theconcert2.mp3'] Test Audios ['UTMA-26.mp3', 'ConscinciasParalelasN3-OsSentidosOSentirEAsNormasParte318-10-1994.mp3']\n"
     ]
    }
   ],
   "source": [
    "print('Train Audios', train_audios_names, 'Test Audios', test_audios_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desired Features list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_names = ['cent', 'rolloff', 'flux', 'zero_crossing_rate', 'rms', 'flatness', 'chroma', 'mfcc', 'bandwidth']\n",
    "# features_names = ['cent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_frames_nums = librosa.time_to_frames(1, sr=sr, hop_length=hop_length, n_fft=n_fft)\n",
    "testing_features_final = np.vstack([np.hstack([moving_method(np.vstack([merged_features[audio_name][feature_name] for feature_name in features_names]), segment_frames_nums, (segment_size//4)//hop_length, method) for audio_name in test_audios_names]) for method in ['mean', 'std']])\n",
    "testing_labels = np.hstack([merged_labels[audio_name] for audio_name in test_audios_names])\n",
    "training_features_final = np.vstack([np.hstack([moving_method(np.vstack([merged_features[audio_name][feature_name] for feature_name in features_names]), segment_frames_nums, (segment_size//4)//hop_length, method) for audio_name in train_audios_names]) for method in ['mean', 'std']])\n",
    "training_labels = np.hstack([merged_labels[audio_name] for audio_name in train_audios_names])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_dp(feature_seq, transition_cost=None, local_cost=None, alpha=0.1):\n",
    "    feature_seq_arr = np.array(feature_seq, ndmin=2)\n",
    "    def state_eq_distance (state_index_0, state_index_1):\n",
    "        return np.sqrt(np.sum((feature_seq_arr[:, state_index_1] - feature_seq_arr[:, state_index_0])**2))\n",
    "    def default_transition_cost (state_index_0, state_index_1):\n",
    "        eq_distance = state_eq_distance(state_index_0, state_index_1)\n",
    "        return 1/eq_distance if eq_distance > 1e-6 else 0\n",
    "    if transition_cost is None: transition_cost = default_transition_cost\n",
    "    if local_cost is None: local_cost = state_eq_distance\n",
    "\n",
    "    costs_pre = np.zeros((feature_seq_arr.shape[1], feature_seq_arr.shape[1], 2))\n",
    "    for i in range(feature_seq_arr.shape[1]):\n",
    "        for j in range(feature_seq_arr.shape[1]):\n",
    "            costs_pre[i, j, 0], costs_pre[i, j, 1] = alpha*transition_cost(i, j), (1-alpha)*local_cost(i, j)\n",
    "\n",
    "    DP_table = [[((1-alpha)*local_cost(0, i), -1) for i in range(feature_seq_arr.shape[1])]]\n",
    "    for i in range(1, feature_seq_arr.shape[1]):\n",
    "        DP_table += [[]]\n",
    "        for j in range(feature_seq_arr.shape[1]):\n",
    "            all_costs = [DP_table[-2][k][0]+costs_pre[k, j, 0]+costs_pre[i, j, 1] for k in range(j+1)]\n",
    "            argmin_cost = np.argmin(all_costs)\n",
    "            DP_table[-1] += [(all_costs[argmin_cost], argmin_cost)]\n",
    "            del all_costs\n",
    "\n",
    "    optimal_path = [np.argmin([cost for cost, state_i in DP_table[-1]])]\n",
    "    i = -1\n",
    "    while i > -feature_seq_arr.shape[1]:\n",
    "        optimal_path = [DP_table[i][optimal_path[0]][1]] + optimal_path\n",
    "        i -= 1\n",
    "    result = feature_seq_arr[:, optimal_path]\n",
    "    return result\n",
    "\n",
    "def moving_classification_dp(feature_seq, window_length, transition_cost=None, local_cost=None, alpha=0.1):\n",
    "    improved_feature_seq = np.array(feature_seq.copy(), ndmin=2)\n",
    "    i = 0\n",
    "    while i < improved_feature_seq.shape[1]:\n",
    "        improved_feature_seq[:, i:i+window_length] = classification_dp(improved_feature_seq[:, i:i+window_length], transition_cost, local_cost, alpha)\n",
    "        i += window_length\n",
    "    return improved_feature_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93     15778\n",
      "           1       0.84      0.84      0.84      6911\n",
      "\n",
      "    accuracy                           0.90     22689\n",
      "   macro avg       0.89      0.89      0.89     22689\n",
      "weighted avg       0.90      0.90      0.90     22689\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = LinearDiscriminantAnalysis()\n",
    "clf.fit(training_features_final.T, training_labels)\n",
    "predicts = clf.predict(testing_features_final.T)\n",
    "transforms = clf.transform(testing_features_final.T)\n",
    "print(classification_report(testing_labels, predicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93     15778\n",
      "           1       0.89      0.77      0.83      6911\n",
      "\n",
      "    accuracy                           0.90     22689\n",
      "   macro avg       0.90      0.86      0.88     22689\n",
      "weighted avg       0.90      0.90      0.90     22689\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = LinearDiscriminantAnalysis()\n",
    "clf.fit(normalizing(training_features_final.T), training_labels)\n",
    "predicts = clf.predict(normalizing(testing_features_final.T))\n",
    "transforms = clf.transform(normalizing(testing_features_final.T))\n",
    "print(classification_report(testing_labels, predicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7faaf2d227d0>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# times = librosa.frames_to_time(range(500), sr=sr, n_fft=s, hop_length=segment_size//2)\n",
    "plt.plot(predicts[:700])\n",
    "plt.plot(testing_labels[:700])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97     15778\n",
      "           1       0.96      0.89      0.92      6911\n",
      "\n",
      "    accuracy                           0.95     22689\n",
      "   macro avg       0.95      0.94      0.95     22689\n",
      "weighted avg       0.95      0.95      0.95     22689\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SVM = svm.SVC()\n",
    "SVM.fit(moving_classification_dp(clf.transform(normalizing(training_features_final.T)).T, 100, alpha=0.99).T, training_labels)\n",
    "dp_transform = moving_classification_dp(clf.transform(normalizing(testing_features_final.T)).T, 100, alpha=0.99).T\n",
    "dp_predicts = SVM.predict(dp_transform)\n",
    "print(classification_report(testing_labels, dp_predicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa73299add0>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "plt.plot(transforms[:1000])\n",
    "plt.plot(dp_transform[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9e62da24a0>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(dp_predicts[2500:3700]*0.7)\n",
    "plt.plot(testing_labels[2500:3700])\n",
    "plt.plot(predicts[2500:3700]*0.4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
